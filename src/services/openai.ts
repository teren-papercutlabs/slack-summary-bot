import OpenAI from "openai";
import { Logger } from "../utils/logger";

export class OpenAIService {
  private static instance: OpenAIService;
  private client: OpenAI;

  private constructor() {
    // Detailed API key validation
    const apiKey = process.env.OPENAI_API_KEY;
    console.log("OpenAIService constructor - Validating API key");

    if (!apiKey) {
      Logger.error({
        message: "OPENAI_API_KEY environment variable is not set",
        envKeys: Object.keys(process.env).filter(
          (key) => !key.toLowerCase().includes("key")
        ),
        functionName: "OpenAIService.constructor",
        nodeEnv: process.env.NODE_ENV,
        cwd: process.cwd(),
      });
      throw new Error("OPENAI_API_KEY environment variable is not set");
    }

    // Validate API key format
    const trimmedKey = apiKey.trim();
    const keyValidation = {
      originalLength: apiKey.length,
      trimmedLength: trimmedKey.length,
      startsWithSk: trimmedKey.startsWith("sk-"),
      hasWhitespace: /\s/.test(apiKey),
      isExpectedLength: trimmedKey.length > 40, // OpenAI keys are typically longer than 40 chars
    };

    Logger.info({
      message: "OpenAI API key validation",
      validation: keyValidation,
      functionName: "OpenAIService.constructor",
    });

    if (!keyValidation.startsWithSk || !keyValidation.isExpectedLength) {
      Logger.error({
        message: "Invalid OpenAI API key format",
        validation: keyValidation,
        functionName: "OpenAIService.constructor",
      });
      throw new Error(
        "Invalid OpenAI API key format - must start with 'sk-' and be of sufficient length"
      );
    }

    this.client = new OpenAI({
      apiKey: trimmedKey,
    });

    // Test if client was initialized properly
    Logger.info({
      message: "OpenAI client initialized",
      clientExists: !!this.client,
      functionName: "OpenAIService.constructor",
    });
  }

  public static getInstance(): OpenAIService {
    if (!OpenAIService.instance) {
      OpenAIService.instance = new OpenAIService();
    }
    return OpenAIService.instance;
  }

  /**
   * Generates a response using GPT-4 for Slack output
   * @param content The article content to analyze
   * @returns The formatted response text
   */
  public async generateResponse(content: string, url: string): Promise<string> {
    try {
      Logger.info({
        message: "Generating GPT response",
        contentLength: content.length,
        functionName: "OpenAIService.generateResponse",
      });

      const prompt = `Analyze this article and provide a summary in Slack markdown format:

1. Format rules:
   - Use Slack markdown (*bold*, _italic_)
   - The title of the article should also be a link to the article.
   - Only use *bold* for the article title and key point headings (e.g. *Key points* and each numbered bullet title).
   - Don‚Äôt start points with ‚ÄúThis article‚Ä¶‚Äù

2. Summary guidelines:
   - Audience: Technical readers at a small startup (engineers, AI leads, and CTOs) building AI-powered products or using AI in their dev workflows.
   - Focus on specific engineering decisions, workflows, automation strategies, and quantitative outcomes.
   - Avoid generic or high-level summaries. Prioritize details like pipeline structure, token usage, prompt iteration, retry mechanisms, and team-wide strategies.
   - The reader should walk away knowing what made this implementation *work* ‚Äî not just what was done.
   - Keep it clear enough that a junior dev could understand it, but sharp enough that a CTO would learn something new.
   - When technical terms are defined outside what a junior dev to know, explain those terms e.g. "Approximate Nearest Neighbor (ANN) solutions, specifically the Inverted File Index (IVF), to manage real-time updates efficiently." and "The team chose IVF over HNSW for its balance between speed and performance" are too technical without context and explanation.

3. End with a *Practical application:* section.
   - Be opinionated. Evaluate which aspects are genuinely useful or replicable for a small team ‚Äî and which are overkill.
   - Suggest concrete adaptations for smaller teams with limited time and tooling.
   - If something is clever, call it out. If it‚Äôs over-engineered, say so.
   - Where possible, suggest a simpler or leaner implementation of the same core ideas.

4. FOLLOW THIS EXACT FORMAT ‚Äì NO DEVIATIONS:

<{article url}|*{article title}*>

*Summary:* {2‚Äì3 sentence technical summary ‚Äî what was done, what made it notable, and how it was achieved}

*Key points*
1. *{Titled point}.* {On the same line, include the detail. Focus on architecture, technical decisions, automation patterns, data used, or results.}
2. *{Another insight}.* {Same style ‚Äî concrete, concise, insightful.}
3. ...

*Practical application:* {Tailored, opinionated take. What would a small dev team actually do with this? What to borrow? What to skip?}

---

üìâ Bad Example (Too Generic):

<https://example.com|*Some Company Migrated Tests to RTL*>

*Summary:* This article describes how a team migrated from Enzyme to RTL. They used LLMs and finished it faster than expected.

*Key points*
1. *They used LLMs.* The team used LLMs to help with the migration.
2. *It was faster than manual work.* It saved time and effort.
3. *They structured the process.* The team followed a structured approach.

*Practical application:* Consider using LLMs in your dev work. It might help you move faster.

üëé Why this is bad:
- Vague summaries (‚Äúused LLMs‚Äù ‚Äî how?)
- No mention of pipeline structure, retries, token limits, success rates
- Practical application is empty calories: no opinion, no adaptation advice

---

üìà Good Example (What You Should Aim For):

<https://airbnb.io/test-migration|*Airbnb Migrated 3.5K Tests with LLMs in 6 Weeks*>

*Summary:* Airbnb used LLMs to automate 97% of a 3.5K-file test migration from Enzyme to React Testing Library, compressing 1.5 years of manual work into 6 weeks. By designing a modular, retryable pipeline and progressively expanding prompt context, they preserved test intent and code coverage while scaling migration throughput.

*Key points*
1. *Modular pipeline via state machine.* Files flowed through discrete validation/refactor steps modeled as a state machine, enabling parallelism and controlled error handling. This structure allowed granular visibility into failures and the ability to retry only the failing step, without reprocessing the entire file.
2. *Aggressive retries with dynamic prompts.* Failed steps triggered automated retries, with each attempt incorporating updated error context and prior file diffs. Many files succeeded within 10 attempts, using what was essentially a brute-force strategy that still saved massive amounts of developer time.
3. *Scaling context to 100K tokens for tricky files.* For tests with custom setups or cross-file dependencies, prompts were expanded to include related test files, domain-specific migration rules, and working examples. This helped the LLM infer architectural patterns and avoid breaking intended test behavior.
4. Iterative tuning loop: sample, tune, sweep. Airbnb analyzed a sample of failed migrations to identify common error patterns (‚Äúsample‚Äù), adjusted prompts and scripts to address those issues (‚Äútune‚Äù), and then reprocessed the full set with the improvements (‚Äúsweep‚Äù). This loop helped raise the automation success rate from 75% to 97%, systematically knocking out edge cases and long-tail failures.

*Practical application:* If you're migrating 100+ test files, a retryable step-based pipeline is worth replicating ‚Äî even without LLMs. For smaller teams, start with 2‚Äì3 validation steps and basic retries using OpenAI functions or bash scripts. Skip the 100K token prompts unless you're seeing complex failure modes; instead, focus on tight few-shot examples and codebase-specific heuristics. Don‚Äôt over-engineer ‚Äî aim for fast feedback loops and rerunability.

---

Use the structure and depth of the *Good Example* as your reference. Match the tone, format, and level of detail exactly.

Article content:
${content}

Article URL (only to be used for the article title link):
${url}
`;

      const response = await this.client.chat.completions.create({
        model: "gpt-4o", // 4o is intended, do not fix this
        messages: [
          {
            role: "system",
            content:
              "You are a precise, insightful, and experienced software developer summarizing a technical article for a small dev team building AI products. Your audience includes junior developers and CTOs. Your job is to distill high-signal insights, focusing on implementation details, clever techniques, and patterns worth learning from. Be concise, but don‚Äôt shy away from nuance or explaining technical concepts. Use Slack markdown. Point out where the article is especially helpful‚Äîor where it overreaches.",
          },
          {
            role: "user",
            content: prompt,
          },
        ],
        temperature: 0.7,
        max_tokens: 1500,
      });

      const responseText = response.choices[0]?.message?.content;
      if (!responseText) {
        throw new Error("No response generated by OpenAI");
      }

      Logger.info({
        message: "Successfully generated GPT response",
        responseLength: responseText.length,
        functionName: "OpenAIService.generateResponse",
      });

      return responseText;
    } catch (error) {
      Logger.error({
        message: "Failed to generate GPT response",
        error: error instanceof Error ? error.message : "Unknown error",
        stack: error instanceof Error ? error.stack : undefined,
        functionName: "OpenAIService.generateResponse",
      });
      throw error;
    }
  }
}
